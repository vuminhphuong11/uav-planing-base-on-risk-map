{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import heapq\n",
    "from scipy.ndimage import sobel\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from skimage.measure import block_reduce\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu độ cao từ file GeoTIFF\n",
    "file_path = r\"C:\\Users\\Admin\\Downloads\\D23022025.tif\"\n",
    "with rasterio.open(file_path) as dataset:\n",
    "    elevation = dataset.read(1)  # Lấy kênh độ cao\n",
    "    profile = dataset.profile\n",
    "\n",
    "# Tính toán độ dốc bằng đạo hàm Sobel3\n",
    "dx = sobel(elevation, axis=1)  # Gradient theo trục x\n",
    "dy = sobel(elevation, axis=0)  # Gradient theo trục y\n",
    "slope = np.hypot(dx, dy)  # Độ dốc tổng hợp\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "elevation_norm = (elevation - np.min(elevation)) / (np.max(elevation) - np.min(elevation))\n",
    "slope_norm = (slope - np.min(slope)) / (np.max(slope) - np.min(slope))\n",
    "\n",
    "# Xây dựng bản đồ rủi ro riêng lẻ\n",
    "risk_elevation = np.zeros_like(elevation_norm)\n",
    "risk_slope = np.zeros_like(slope_norm)\n",
    "\n",
    "risk_elevation[elevation_norm < 0.3] = 0  # An toàn\n",
    "risk_elevation[(elevation_norm >= 0.3) & (elevation_norm < 0.7)] = 0.5  # Trung bình\n",
    "risk_elevation[elevation_norm >= 0.7] = 1  # Nguy hiểm\n",
    "\n",
    "risk_slope[slope_norm < 0.3] = 0  # An toàn\n",
    "risk_slope[(slope_norm >= 0.3) & (slope_norm < 0.7)] = 0.5  # Trung bình\n",
    "risk_slope[slope_norm >= 0.7] = 1  # Nguy hiểm\n",
    "\n",
    "\n",
    "risk_combined = np.maximum(risk_elevation, risk_slope)\n",
    "\n",
    "# Hàm chuyển dữ liệu rủi ro thành ảnh màu\n",
    "def generate_risk_map(risk_data):\n",
    "    risk_map = np.zeros((*risk_data.shape, 3))  # Ảnh màu (H, W, 3)\n",
    "    risk_map[risk_data < 0.3] = [0, 0.5, 0]  # Xanh (An toàn)\n",
    "    risk_map[(risk_data >= 0.3) & (risk_data < 0.7)] = [1, 1, 0]  # Vàng (Trung bình)\n",
    "    risk_map[risk_data >= 0.7] = [1, 0, 0]  # Đỏ (Nguy hiểm)\n",
    "    return risk_map\n",
    "\n",
    "# Tạo ảnh màu cho 3 bản đồ\n",
    "risk_map_elevation = generate_risk_map(risk_elevation)\n",
    "risk_map_slope = generate_risk_map(risk_slope)\n",
    "risk_map_combined = generate_risk_map(risk_combined)\n",
    "\n",
    "# Hiển thị cả 3 bản đồ\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(risk_map_elevation)\n",
    "axes[0].set_title(\"Bản đồ rủi ro theo độ cao\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(risk_map_slope)\n",
    "axes[1].set_title(\"Bản đồ rủi ro theo độ dốc\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(risk_map_combined)\n",
    "axes[2].set_title(\"Bản đồ rủi ro tổng hợp\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển bản đồ rủi ro thành grayscale\n",
    "def generate_grayscale_risk_map(risk_data):\n",
    "    grayscale_map = np.zeros_like(risk_data, dtype=np.uint8)\n",
    "    grayscale_map[risk_data < 0.3] = 150 # An toàn (màu xám nhạt)\n",
    "    grayscale_map[(risk_data >= 0.3) & (risk_data < 0.7)] = 100 # Trung bình (xám trung bình)\n",
    "    grayscale_map[risk_data >= 0.7] = 50  # Nguy hiểm (xám đậm)\n",
    "    return grayscale_map\n",
    "\n",
    "# Tạo ảnh grayscale từ risk_map_combined\n",
    "grayscale_risk_map = generate_grayscale_risk_map(risk_combined)\n",
    "\n",
    "# Hiển thị ảnh grayscale\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(grayscale_risk_map, cmap='gray')\n",
    "plt.title(\"Bản đồ rủi ro (Grayscale)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# DQN Agent\n",
    "class DQN_Agent:\n",
    "    def __init__(self, state_size, action_size, model_path=\"dqn_model.h5\"):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.002\n",
    "        self.model = self.build_model()\n",
    "        self.model_path = model_path\n",
    "\n",
    "        # Load mô hình nếu có\n",
    "        self.load_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Dense(24, input_dim=self.state_size, activation='relu'),\n",
    "            Dense(24, activation='relu'),\n",
    "            Dense(self.action_size, activation='linear')\n",
    "        ])\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def save_model(self):\n",
    "        \"\"\" Lưu trọng số mô hình và epsilon để tiếp tục huấn luyện \"\"\"\n",
    "        self.model.save(self.model_path)\n",
    "        with open(self.model_path.replace(\".h5\", \"_epsilon.txt\"), \"w\") as f:\n",
    "            f.write(str(self.epsilon))\n",
    "        print(f\"Đã lưu mô hình vào {self.model_path}\")\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\" Tải mô hình đã lưu nếu tồn tại \"\"\"\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.model = tf.keras.models.load_model(self.model_path)\n",
    "            epsilon_path = self.model_path.replace(\".h5\", \"_epsilon.txt\")\n",
    "            if os.path.exists(epsilon_path):\n",
    "                with open(epsilon_path, \"r\") as f:\n",
    "                    self.epsilon = float(f.read().strip())\n",
    "            print(f\"Đã tải mô hình từ {self.model_path}, Epsilon: {self.epsilon:.4f}\")\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        state = np.array(state).reshape(1, -1)\n",
    "        act_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "    \n",
    "    def train(self, batch_size=32):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                next_state = np.array(next_state).reshape(1, -1)\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state, verbose=0))\n",
    "            state = np.array(state).reshape(1, -1)\n",
    "            target_f = self.model.predict(state, verbose=0)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "class UAV_Env:\n",
    "    def __init__(self, risk_map, start, goal):\n",
    "        self.risk_map = risk_map\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "        self.state = start\n",
    "        self.actions = [\n",
    "            ((0, 1), 1), ((1, 0), 1), ((0, -1), 1), ((-1, 0), 1),  # Lên, Xuống, Trái, Phải\n",
    "            ((1, 1), 1.4), ((1, -1), 1.4), ((-1, 1), 1.4), ((-1, -1), 1.4) # Đường chéo\n",
    "        ]\n",
    "        self.rows, self.cols = risk_map.shape[:2]\n",
    "        self.steps_in_risk = 0  # Đếm số bước UAV đi trong vùng nguy hiểm\n",
    "        self.MAX_STEPS_IN_RISK = 6  # Giới hạn số bước UAV có thể tồn tại trong vùng nguy hiểm\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.start\n",
    "        self.steps_in_risk = 0  # Reset bộ đếm vùng nguy hiểm khi bắt đầu lại\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\" Thực hiện hành động và trả về (next_state, reward, done) \"\"\"\n",
    "        (dr, dc), move_cost = self.actions[action]\n",
    "        row, col = self.state\n",
    "        new_row, new_col = row + dr, col + dc\n",
    "        if 0 <= new_row < self.rows and 0 <= new_col < self.cols:\n",
    "            self.state = (new_row, new_col)  # Cập nhật vị trí UAV\n",
    "\n",
    "        old_distance = abs(row - self.goal[0]) + abs(col - self.goal[1])\n",
    "        new_distance = abs(new_row - self.goal[0]) + abs(new_col - self.goal[1])\n",
    "\n",
    "        if self.state == self.goal:\n",
    "            reward = 5000  # Tăng phần thưởng để khuyến khích UAV đến đích\n",
    "            done = True\n",
    "        elif self.risk_map[self.state] >= 0.8:\n",
    "            if new_distance < old_distance:\n",
    "                self.steps_in_risk -= 1\n",
    "                reward = -1 - move_cost  # Trừ thêm chi phí di chuyển\n",
    "            else:\n",
    "                self.steps_in_risk += 1\n",
    "                reward = -10 - move_cost\n",
    "            done = self.steps_in_risk >= self.MAX_STEPS_IN_RISK\n",
    "        else:\n",
    "            if new_distance < old_distance:\n",
    "                reward =  (old_distance - new_distance) * 2 - move_cost  # Trừ chi phí di chuyển\n",
    "            else:\n",
    "                reward =  - move_cost\n",
    "            done = False\n",
    "\n",
    "        return self.state, reward, done\n",
    "\n",
    "    def render(self, path=[]):\n",
    "        img = (self.risk_map * 255).astype(np.uint8)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        for (r, c) in path:\n",
    "            cv2.circle(img, (c, r), 1, (0, 255, 255), -1)  # Đường đi màu Cyan\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.scatter(self.start[1], self.start[0], color=\"green\", marker=\"o\", label=\"Start\")\n",
    "        plt.scatter(self.goal[1], self.goal[0], color=\"red\", marker=\"x\", label=\"Goal\")\n",
    "        plt.legend()\n",
    "        plt.title(\"DQN UAV Pathfinding\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Load Risk Map\n",
    "risk_map = risk_map_combined[:, :, 0]\n",
    "start = (50, 50)\n",
    "goal = (500, 750)\n",
    "\n",
    "env = UAV_Env(risk_map, start, goal)\n",
    "agent = DQN_Agent(state_size=2, action_size=len(env.actions))\n",
    "\n",
    "episodes = 50\n",
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    path = []\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        path.append(state)\n",
    "    \n",
    "    agent.train()\n",
    "    \n",
    "    print(f\"Episode {e+1}/{episodes}, Score: {total_reward}, Epsilon: {agent.epsilon:.4f}\")\n",
    "    \n",
    "    if e % 5 == 0:\n",
    "        env.render(path)  # UAV Environment\n",
    "    \n",
    "    if e % 10 == 0:\n",
    "        agent.save_model()  # Lưu mô hình mỗi 10 episodes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
